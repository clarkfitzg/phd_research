## Reflections and Lessons Learned

Wed Nov 29 07:10:33 PST 2017

ddR is on my radar again, since they have another intern working on it, and
people have been asking.

### Social

__Ownership__ Who will maintain ddR and push it forward? Officially the
repo is on Vertica's Github site, but the contributors have since left
Vertica. So further efforts are probably going to require forking the
project.

__Motivating Use Cases__ Where will ddR be used in the wild? Who are the
users who will benefit from this? I believe the intended audience was the
few highly technical people involved in the working group.

Spark - they don't have efficient ML algos even in their own system.

### Technical

Bryan Lewis said something along the lines of: "Maybe R itself is
expressive enough." He meant that R's class system suffices as an
abstraction layer. [gpuR](https://github.com/cdeterman/gpuR) is a nice
example of this.

__Abstraction__ It's not clear that the abstraction layer in ddR adds
value. I found that I needed to thoroughly understand both ddR and the
underlying distributed system in order to use them. So it didn't abstract
away the details of the distributed system.

__Common Implementation__


## Personal

Fri Oct  7 11:41:18 PDT 2016

The project has been done for a few weeks, having a final call this
afternoon.

Now I am not convinced that `ddR`'s model is necessary. Distributed systems
are so different, this seems excessively ambitious to work well and
perform.

Sign a contract and get paid first. Verbal agreements insufficient. Pay
hassles every single time and late payments were not fun.

I was under the impression that this was much more
mature than it is. 

Who owns the project? If it's a company, are they motivated to maintain it? If it's
an individual, are they likely to stick it out?

Use the software before starting work on it. Even a very simple application
to real data analysis revealed serious memory and speed problems with the
base implementation. 

Be careful with low activity. Although there was buzz in the forms of blogs
and Github watchers, I'm not aware of applications of the
software on anything other than simulated data. And there was no activity
on the Github account in 8 months or so.

Choose dependencies wisely. I thought I was doing this when by keeping an
open dialogue with RStudio, but they pulled the rug out from us by
incorporating `sparkapi` into `sparklyr`. In my mind they should still be
separate packages.

Check for code quality. This is important for public projects. Is one
naming scheme CamelCase or under_score followed? Are functions easy to read
and composed from nice modular units? How much code is repeated? Are there
functions or classes with no apparent purpose? Is the user facing API
clearly defined and minimal?
