{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet\n",
    "\n",
    "Summarizing the [parquet documentation](https://parquet.apache.org/documentation/latest/):\n",
    "\n",
    "- Goal is interoperability across Hadoop ecosystem\n",
    "- Compression can be specified per column\n",
    "- Handles complex nested data structures (similar to XML)\n",
    "- Follows the 2010 Google Dremel paper\n",
    "\n",
    "Column chunks are guaranteed to be contiguous within a row group. Here's a hierarcy for a table with 2 columns.\n",
    "```\n",
    "File\n",
    "    Row Group 1\n",
    "        Column Chunk 1\n",
    "        Column Chunk 2\n",
    "    Row Group 2\n",
    "        Column Chunk 1\n",
    "        Column Chunk 2        \n",
    "    Row Group 3\n",
    "        ...\n",
    "```\n",
    "Docs recommend configuring 1GB row group sizes, corresponding to 1 GB HDFS blocks. \n",
    "\n",
    "- Row based MapReduce runs in parallel across Row Groups\n",
    "- IO runs in parallel across column chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from the top of this page: http://anson.ucdavis.edu/~clarkf/\n",
    "\n",
    "I used conda to install pyarrow: https://anaconda.org/conda-forge/pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the dataset as below is cheap because it only reads the metadata.\n",
    "\n",
    "Metadata is represented with Apache Thrift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pems = pq.ParquetDataset(\"/Users/clark/data/pems/pems_sorted/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schema from the database (Hive) is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow._parquet.ParquetSchema object at 0x11417a288>\n",
       "timeperiod: BYTE_ARRAY UTF8\n",
       "flow1: INT32\n",
       "occupancy1: DOUBLE\n",
       "speed1: DOUBLE\n",
       "flow2: INT32\n",
       "occupancy2: DOUBLE\n",
       "speed2: DOUBLE\n",
       "flow3: INT32\n",
       "occupancy3: DOUBLE\n",
       "speed3: DOUBLE\n",
       "flow4: INT32\n",
       "occupancy4: DOUBLE\n",
       "speed4: DOUBLE\n",
       "flow5: INT32\n",
       "occupancy5: DOUBLE\n",
       "speed5: DOUBLE\n",
       "flow6: INT32\n",
       "occupancy6: DOUBLE\n",
       "speed6: DOUBLE\n",
       "flow7: INT32\n",
       "occupancy7: DOUBLE\n",
       "speed7: DOUBLE\n",
       "flow8: INT32\n",
       "occupancy8: DOUBLE\n",
       "speed8: DOUBLE\n",
       " "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pems.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nulls\n",
    "\n",
    "Quite a bit different than using IEEE NaN or a special bit pattern.\n",
    "\n",
    "> Nullity is encoded in the definition levels (which is run-length encoded). NULL values are not encoded in the data. For example, in a non-nested schema, a column with 1000 NULLs would be encoded with run-length encoding (0, 1000 times) for the definition levels and nothing else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Arrow\n",
    "\n",
    "> Powering Columnar In-Memory Analytics\n",
    "\n",
    "A bold claim... R, Python (Numpy), and Julia all compete in this space.\n",
    "\n",
    "Source: [Arrow Docs](https://arrow.apache.org/)\n",
    "\n",
    "Essentially Arrow is a specification for a memory layout, along with high performance C++ and Java implementations.\n",
    "\n",
    "My initial experiments using it for shared memory were positive.\n",
    "\n",
    "![Common memory](common_memory.png)\n",
    "\n",
    "## Some thoughts\n",
    "\n",
    "To load data from parquet into a high level language one needs to go from parquet to arrow to data structures in X language. Why not load directly from parquet to high level language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "timeperiod: string\n",
       "flow1: int32\n",
       "occupancy1: double\n",
       "station: dictionary<values=int64, indices=int32>\n",
       "-- metadata --\n",
       "org.apache.spark.sql.parquet.row.metadata: {\"type\":\"struct\",\"fields\":[{\"name\":\"timeperiod\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow1\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy1\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed1\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow2\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy2\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed2\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow3\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy3\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed3\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow4\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy4\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed4\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow5\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy5\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed5\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow6\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy6\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed6\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow7\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy7\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed7\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"flow8\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"occupancy8\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}},{\"name\":\"speed8\",\"type\":\"double\",\"nullable\":true,\"metadata\":{}}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pems_table = pems.read([\"timeperiod\", \"flow1\", \"occupancy1\"])\n",
    "pems_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3932049, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata tells us things like the shape\n",
    "pems_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.Column at 0x114099e40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can pull out underlying pieces\n",
    "\n",
    "flow1 = pems_table[1]\n",
    "flow1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataType(int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow1.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1420"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow1.data.num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.lib.Int32Array object at 0x13da43228>\n",
       "[\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0\n",
       "]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow1.data.chunk(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pems_df = pems_table.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeperiod</th>\n",
       "      <th>flow1</th>\n",
       "      <th>occupancy1</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2016 00:00:05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/01/2016 00:00:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/01/2016 00:01:06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/01/2016 00:01:35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/01/2016 00:02:05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>402260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timeperiod  flow1  occupancy1 station\n",
       "0  01/01/2016 00:00:05      0         0.0  402260\n",
       "1  01/01/2016 00:00:35      0         0.0  402260\n",
       "2  01/01/2016 00:01:06      0         0.0  402260\n",
       "3  01/01/2016 00:01:35      0         0.0  402260\n",
       "4  01/01/2016 00:02:05      0         0.0  402260"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pems_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
