% A simple template for Beamer presentations in LaTeX
% 
% To produce pdf run:
%   $ pdflatex beamer.tex 

\documentclass{beamer}
%\usetheme{Singapore}
\usetheme{Boadilla}

% Bibliography
%\usepackage{cite}
\usepackage{biblatex}

\hypersetup{colorlinks=true}

% Show table of contents between sections
\AtBeginSection[]
{
  \begin{frame}
    \frametitle{Table of Contents}
    \tableofcontents[currentsection]
  \end{frame}
}

% Graphics examples
%\centerline{\includegraphics[height=2.5in]{figs/normal.pdf}}
%\includegraphics[width=4in]{figs/makefile.png}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Parallel Computing Through Code Analysis}
\date{\today}
\date{10 May 2017}
\author{Clark Fitzgerald}
\institute{UC Davis}
\titlegraphic{\includegraphics[height=.5\textheight]{../workflow.pdf}}

\frame{\titlepage}

%C Introduce myself
%C Thanks for coming
%C

%\begin{frame}
%    \frametitle{Outline}
%    \tableofcontents
%\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\frametitle{Modern platforms provide incredible computing power.}

%C Showing Hadoop, but it could be any cluster
%C I've worked on all these platforms
%C Why make someone learn all these systems? Domain scientists don't care.
%C

\begin{figure}
            %\hfill
            \includegraphics[width=1.3in]{macbook.jpg}
            %\hfill
            \includegraphics[width=1.3in]{gpu.jpg}
            %\hfill
\end{figure}
\begin{figure}
            %\hfill
            \includegraphics[width=1.3in]{spark.png}
            %\hfill
            \includegraphics[width=1.3in]{aws.png}
            %\hfill
\end{figure}

\pause 

But they require expertise.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The broader goal is for users to write higher level code
    that also performs better.}

%C Conventional wisdom says that for performance you need to go to a lower
%C level. Ie. from R, Rcpp, C, OpenCL, CUDA
%C Extreme example: Ethan approached to design circuits specific
%C to one computation.
%C

    \begin{itemize}
        \item Parallel programming is a means to this end
        \item Compilation is another way
        \item Expertise in system rather than end user
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    % TODO: better title
    \frametitle{We take a holistic approach to the computation.}

%C In contrast, compilation only examines code.
%C

\centerline{\includegraphics[width=.8\textwidth]{../workflow.pdf}}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The R language offers several benefits.}

\centerline{\includegraphics[height=1in]{Rlogo.png}}

    \begin{itemize}
        \item Functional languages simplify parallel computing
        \item Widely used for statistics and data analysis
        \item Supports metaprogramming aka ``programming on the
            language''
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivating Example}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The purpose of this example is to motivate the proposed
    research.}

%C I'm interested in it, and I'd like to see it through
%C NOT the end goal of the project
%C

    \begin{itemize}
        \item Working with Professor Michael Zhang from Civil Engineering
        \item Illustrates complexity when computing with larger data sets
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Loop detectors count vehicle flow, measuring velocity and
    density (time sensor is activated).}

%C Collected in 30 sec intervals
%C Data Exceedingly noisy and dirty
%C 

\centerline{\includegraphics[height=2.5in]{loop_detector.jpg}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

%C CalTrans uses this to study congestion patterns and inform policy
%C Available for public download
%C 

\frametitle{Caltrans Performance Measurement System (PeMS) records loop
    detector data for the whole state.}

    \begin{itemize}
        \item Each sensor measures 3 quantities
        \item Data point every 30 seconds
        \item $43,680$ sensors in California
        \item $\implies$  377 million data points per day
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The \emph{fundamental diagram} in traffic engineering shows
        the relationship between flow and density.}

%C Fundamental diagram allows modeling change in congestion patterns
%C and individual trip times
%C It's a curve fitting problem
%C Research traffic engineers experiment with many possible curves
%C Note that observations are sparse in interesting areas of high density.
%C Maybe 5%
%C 

    \centerline{\includegraphics[height=2.5in]{../../analysis/pems/occ_flow_with_sample.pdf}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Each station has a fundamental diagram, which can be fit in
    parallel.}

%C Paper fit multiple lines minimizing the L1 norm of the residuals
%C Can approximate this with robust linear models- 
%C standard errors get much better if use them for a year
%C They used a handful of stations for 1 day
%C Can do qualitatively different analysis with more data
%C clustering, assessing effect of traffic
%C 

\centerline{\includegraphics[height=2.5in]{many_fundamental_diagram.png}}

Source: Li, Zhang 2011

Using more data allows new types of analysis.

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{Using more data allows new types of analyses.}
%
%    % Policy is especially interesting, because that can potentially be changed
%    % Recommending state wide policy, then why not look at data for the
%    % whole state?
%
%    \begin{itemize}
%        \item Effect of policy such as speed limits and carpool lanes
%        \item Impact of road features such as on/off ramps
%        \item Effect of weather
%        \item Clustering detectors
%    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{R expresses statistical computation well.}

%C I appreciate R's succintness
%C It's a fair amount of work to make this run
%C 

    \centerline{\includegraphics[height=1in]{../../analysis/pems/occ_flow_with_sample.pdf}}

\begin{verbatim}
by(data=single_day, INDICES = station, FUN = my_fd)
\end{verbatim}

    \pause

    \begin{itemize}
        \item For a single day with 377 million observations this can be
            done on a single machine.
        \item A sensible way to run this in parallel is to \texttt{fork()}
            the process after reading in the data.
        \item So you write a bunch of code to do that :)
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Small changes can require totally different
    computations.}

%C Small perturbation of the code / analysis
%C produce large changes in the required computation.
%C It would be much better if a system could figure this out
%C 

    If we compute on one year then this will exceed memory.

\begin{verbatim}
by(data=one_year, INDICES = station, FUN = my_fd)
\end{verbatim}

\pause 

    A different model, such as least squares, may be able to process the
    data as a stream.

\begin{verbatim}
by(data=one_year, INDICES = station, FUN = my_lm_fd)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

%C Ideal case: Everything I'm doing requires moving the data from their
%C servers, so it's necessarily inefficient.
%C General principle: avoiding data movement
%C

    \frametitle{Access to the underlying database may allow us to run code directly inside the
    database.}

\begin{verbatim}
SELECT station, my_fd(...) FROM data GROUP BY station
\end{verbatim}


%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{Lets scale up the computations with parallel programming}
%
%    \begin{itemize}
%        \item Several parallel strategies exist to improve performance
%        \item Which is best depends on the platform and data
%        \item Each one requires deeper knowledge of that particular technology
%        \item Therefore techniques to programmatically identify and use the parallel
%  patterns implicit in code would be valuable
%    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parallel Concepts}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

\frametitle{This simple example shows how to write parallel code in R.}

%C Intentionally simple, but we'll see some complexity
%C This creates an intermediate vector of length n.
%C Fails when n approaches limits of memory.
%C 

Consider computing the mean,

\begin{equation}
    \bar{x} = \frac{1}{n} \sum_{i = 1}^n x_i
\label{eq:mean}
\end{equation}

where the $x_i$'s are i.i.d. $\sim t(d)$. 
    
In R this code is written:

\begin{verbatim}
xbar = mean(rt(n, d))
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{We can express the mean as a weighted mean.}

%C Assume that n can be split evenly, then we can take the mean of the
%C means.
%C 

Suppose $n = n_j p$, where $n_j$ is the chunk size and $p$ is the number of
chunks.

\begin{equation}
    \bar{x} = \frac{1}{n} \sum_{j = 1}^p \sum_{i = 1}^{n_j} x_{ij}
    = \frac{1}{p} \sum_{j = 1}^p \frac{1}{n_j} \sum_{i = 1}^{n_j} x_{ij}
    = \frac{1}{p} \sum_{j = 1}^p \bar{x}_{\cdot j}
\label{eq:mean_partial}
\end{equation}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{The weighted mean can be directly translated into R code.}

\begin{verbatim}

partial_means = replicate(p, mean(rt(n_j, d)))
xbar = mean(partial_means)

\end{verbatim}

\pause 

    \begin{itemize}
        \item While not parallel, this effectively removes the memory limits.
        \item How to choose the $n_j$ and $p$?
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The same computation can be evaluated on many workers
    simultaneously.}

\centerline{\includegraphics[height=3in]{../snow.pdf}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Here is one way to parallelize this code.}

\begin{verbatim}
library(parallel)
p = floor(detectCores(logical = FALSE) / 2)
n_j = n / p
cluster = makeCluster(p)

expr = substitute(mean(rt(n_j, d)),
	list(d = d, n_j = n_j))

partial_means = unlist(
    clusterCall(cluster, eval, expr))

xbar = mean(partial_means)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{We're considering a system that transforms expressions.}

\hfill

    \textbf{Input:}

\begin{verbatim}
xbar = mean(rt(n, d))
\end{verbatim}

\hfill

    \textbf{Output:} (omitting boilerplate)

\begin{verbatim}
p = floor(detectCores(logical = FALSE) / 2)

expr = substitute(mean(rt(n_j, d)),
    list(d = d, n_j = n_j))

partial_means = clusterCall(cluster, eval, expr)
xbar = mean(partial_means)
\end{verbatim}

\hfill

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{This can be difficult because R is implemented in C.}

\begin{verbatim}
> head(rt, 4)

1 function (n, df, ncp)
2 {
3     if (missing(ncp))
4         .Call(C_rt, n, df)
\end{verbatim}

\pause

    Options:

    \begin{itemize}
        \item Start from \texttt{replicate(p, mean(rt(n\_j, d)))}
        \item Allow users to indicate how \texttt{rt} is vectorized
        \item Analyze the preprocessed C code
        \item Rewrite the C code in R, then analyze the R code
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Code Analysis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{\{Code, Data, Platform\} together determine the execution
    strategy.}

\begin{figure}
            \includegraphics[width=1.4in]{code_screen.png}
            \hfill
            \includegraphics[width=1in]{database.png}
            \hfill
            \includegraphics[width=1.4in]{gpu.jpg}
\end{figure}

%    \begin{itemize}
%    \item \textbf{Code} script to be executed
%    \item \textbf{Data} in-memory, files, database, etc
%    \item \textbf{Platform} 4 core laptop, server with GPU, Spark cluster,
%        etc
%    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{CodeDepends is a tool for analyzing code as a data
    structure.}

    % Written by Duncan, Gabe Becker, Deb Nolan
    % Motivated by DSI

    Consider this script:

\begin{verbatim}
params = read.csv('params.csv')
data = read.csv('data.csv')
sim = simulate(params, 1000000)
joined = merge(data, sim)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The expression graph represents the dependencies between
    expressions.}

    \centerline{\includegraphics[height=2.5in]{../codegraph.pdf}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}


\frametitle{Is it worth it to go parallel?}

    \centerline{\includegraphics[height=2.5in]{../compute_times/overhead}}

% This has to be answered for every piece of code, every time

% If there wasn't any overhead, we would use it all the time for
% everything.

% If you start up a process, you want to keep it around

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\frametitle{Given an existing SNOW cluster with 2 workers we see benefits
    from parallelization when $n > 4000$.}

\centerline{\includegraphics[height=2.5in]{../compute_times/ser_vs_par.pdf}}

Timings on a 3.4 GHz Intel i3 CPU

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Factors to consider}

\textbf{Parameters}
\begin{itemize}
    \item number of processor cores to use
    \item size of each chunk
    \item which functions to combine in one processing step
\end{itemize}

\textbf{Constraints}
\begin{itemize}
    \item number of cores available
    \item network bandwidth
    \item disk IO speed
    \item available memory
\end{itemize}

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{Estimating time required for the map reduce paradigm with many workers}
%
%    % TODO: Get Duncan's feedback
%\begin{itemize}
%    \item $w_i$ worker startup time
%    \item $c(x_i)$ communication time to send $x_i$ and receive $f(x_i)$.
%    \item $e(x_i)$ time to evaluate $f(x_i)$ on a worker.
%\end{itemize}
%
%Then we minimize
%\[
%    \max_{x_i} \left( w_i + c(x_i) + e(x_i) \right)
%\]
%for $x = (x_1, \dots, x_m)$, a partition of $x$ into chunks.

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{If we want to compute on out of memory data:}
%
%\begin{itemize}
%    \item $w$ worker startup time
%    \item $l$ latency in communication
%    \item $t(n_j)$ time to compute on $n_j$ elements
%    \item $m(n_j)$ memory required to compute on $n_j$ elements
%\end{itemize}
%
%Then we minimize
%\[
%    w + 2l + \max (t(n_j))
%\]
%such that 
%
%\begin{itemize}
%    \item $\sum n_j = n$ total data points
%\end{itemize}
%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Idiomatic R already expresses computation in a natural
    parallel way through ``apply'' functions.}

\begin{verbatim}
x = replicate(5, rnorm(n_j), simplify = FALSE)

partialmeans = lapply(x, mean)

by(data, INDICES = station, FUN = piecewise_rlm)
\end{verbatim}

Also
\begin{verbatim}
apply, sapply, tapply, by, mapply, Map, vapply, outer
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Layers mark ways for users to write parallel code for one
    platform.}

\begin{itemize}
    \item \textbf{User R Packages}: foreach, future, partools, ddR, biganalytics, RevoScaleR
    \item \textbf{R Layer}: SNOW, parallel, bigmemory, Rmpi, RCUDA
    \item \textbf{Operating System}: threads, processes, *NIX fork(), memory maps, network sockets, MPI
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{How can we transform R code into a lower layer?}

% Potentially we can transform to any of these layers

\centerline{\includegraphics[height=.8\textheight]{../layers.pdf}}

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%   \frametitle{Preserving language semantics can be challenging.}
%
%    For example, R's dynamic lookups 
%
%\begin{verbatim}
%
%    f = function() 0
%    g = function() f() + 1
%    f = function() 10
%    g()                     # Returns 11!
%
%\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Knowledge of the data allows us to generate more
    specialized code.}

    \begin{itemize}

	\item File size
	\item Dimensions of table / matrix / array
	\item Column classes
	\item Randomized rows
	\item Sorted / grouped
	\item Possible values for factor
	\item Indexed
	\item Including sufficient statistics

    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Example: a data format that facilitates sampling.}

    % File seeking takes microseconds

station, flow, occupancy, time
\begin{verbatim}
1       12      0.087    09:57:00
1       14      0.092    14:29:30

...

7       14      0.088    16:32:30
7       11      0.090    17:12:00
\end{verbatim}

    \begin{itemize}

        \item ASCII fixed width format, $c$ characters (bytes) per row
        \item sorted on station, then occupancy
        \item $r$ rows per station
        \item $\implies$ new stations begin at byte $i \times c \times r$

    \end{itemize}

%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}[fragile]
%
%    \frametitle{One challenge is how to properly abstract ``data''.}
%
%    Some options:
%
%    \begin{itemize}
%        \item Iterators of chunks as in R's \texttt{iterators} package
%        \item ``file-like'' objects from *NIX
%        \item Pick one serialization format, ie. CSV, feather
%        \item Abstract parallel data structures
%    \end{itemize}
%
%    \pause
%
%    \begin{itemize}
%        \item Maintain custom metadata objects?
%        \item Only focus on data frames / tables?
%    \end{itemize}
%
%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{Map and reduce functions}
%
%    Let $f: x \rightarrow y$ and $x = O(n)$, a data structure with $O(n)$
%    elements.
%
%    \begin{itemize}
%        \item If $y$ is also $O(n)$ then we can call $f$ a \textbf{Map} function.
%
%        \item Example: $f(x) = 2x$ for $x \in R^n$.
%
%    % This is vectorization in R
%    
%        \item If $y$ is $O(1)$ then $f$ is a \textbf{Reduce} function.
%
%        \item Example: $f(x) = \sum_{i = 1}^n x_i$
%    \end{itemize}


%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}
%
%    \frametitle{Compiled R code provides even more efficiency.}
%
%\begin{enumerate}
%    \item Parallelization will complement efforts to compile R
%    \item Compiled code potentially allows the use of shared memory threads
%    \item May follow the OpenCL kernel model
%\end{enumerate}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

%    \frametitle{Follow up on the sensor example}
%
%    Program should:
%
%\begin{enumerate}
%    \item Remove any observations it can
%    \item Reorganize files on disk based on station ID
%    \item Apply function to each station ID file
%\end{enumerate}
%
%\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{frame}

    \frametitle{We propose using \{Code, Data, Platform\} to determine a
    parallel execution strategy.}

\begin{figure}
            \includegraphics[width=1.4in]{code_screen.png}
            \hfill
            \includegraphics[width=1in]{database.png}
            \hfill
            \includegraphics[width=1.4in]{gpu.jpg}
\end{figure}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Related Work}

%C I like my data dirty
%C 

\begin{itemize}
    \item Related CS literature mostly focused on algorithmic applications
        and lower level languages
    \item Software such as Dask, Theano, Tensorflow require the user to build
        computation graphs
    \item Primarily focused on numeric arrays
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{The next step is to build a prototype of the system.}

    Specifically beginning with:

\begin{itemize}
    \item \emph{code}: Apply family of functions
    \item \emph{data}: Files on disk exceeding main memory
    \item \emph{platform}: Single server
\end{itemize}

Then test it with the traffic sensor data.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

\frametitle{Next I'd like to extend this to platforms that store data}

\begin{verbatim}
SELECT station, my_rlm(...) FROM data GROUP BY station
\end{verbatim}


\begin{itemize}
    \item Better data locality
    \item Many use cases
    \item Connection to compilation
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Acknowledgements}

\begin{itemize}
    \item Faculty members
    \item Data Science Institute Affiliates and statistics students for
        applications and feedback
    \item Special thanks to Professors Duncan Temple Lang and Michael Zhang
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Questions?}
    \centerline{\includegraphics[height=2.5in]{../workflow.pdf}}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Additional Slides}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{More Applications}

    % TODO: Expand on each of these

\begin{itemize}
    \item Benford test on election campaign contribution data
        %\cite{tam2007breaking}
    \item Forest greenness satellite imagery (Andrew Latimer)
    \item Simulating spread of disease (Nistara Randhawa)
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Last summer I worked on the Distributed Data Structures in
R (DDR) project}

% Expert users had some valid critiques and suggestions
% Bryan Lewis- Maybe R is all the API we need?

\begin{itemize}
    \item Relevant experience
    \item Idea: an abstraction layer for distributed and parallel data structures
    \item Created R lists and apply type functions to run on Spark
\end{itemize}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{How do we detect if a function in R is vectorized, and in
    which arguments?}

    \texttt{rnorm()} is vectorized in the last two arguments, but
    semantically different for a vector in the first argument.

\begin{verbatim}
> rnorm(5, mean = c(1, 2), sd = c(2, 10, 200))
[1]   0.2134756  -4.1137221 256.0094734   0.4562226 -10.3855374
\end{verbatim}

It's all C Code.

\begin{verbatim}
> rnorm
function (n, mean = 0, sd = 1)
.Call(C_rnorm, n, mean, sd)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{An iterator produces data on demand}

    \centerline{\includegraphics[height=1.6in]{../iterator.pdf}}

    \begin{itemize}
        \item Most flexible of the above options
        \item Natural in pipeline parallel model
        \item Operate well with high performance IO libraries
    \end{itemize}

    \pause

    \begin{itemize}
        \item Unfamiliar to R programmers
        \item Not ideal if you need the whole data set
    \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{R in a database}

    Suppose we want to call the vectorized function $f()$. If $f()$ is
    available both in R and the database then we have two options:

\begin{verbatim}
    Option 1: Run f inside database, returning result
    
    dbGetQuery(con,"SELECT f(x) FROM mydata;")

    Option 2: First fetch x, then call f within R

    f(dbGetQuery(con,"SELECT x FROM mydata;"))
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{By ``programming on the language'' we can modify existing
    code.}

\begin{verbatim}
lapply_to_mclapply = function(expr)
{
    # Changes lapply to parallel::mclapply
    lapply = quote(parallel::mclapply)
    expr = force(expr)
    # Following Wickham's Advanced R book
    call = substitute(substitute(expr))
    eval(call)
}

> e1 = quote(xmeans <- lapply(x, mean))
> lapply_to_mclapply(e1)
xmeans <- parallel::mclapply(x, mean)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]

    \frametitle{Pipeline parallelism is like a factory assembly line.}

\centerline{\includegraphics[width=\textwidth]{../pipeline.pdf}}

\begin{verbatim}
# Worker 1
x_chunk = rnorm(n_j)
serialize(x_chunk, worker2)


# Worker 2
x_chunk = unserialize(worker1)
partial_means[i] = mean(x_chunk)
\end{verbatim}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

    \frametitle{Simple row based sampling misses the important areas of high
    density.}

    \centerline{\includegraphics[height=2.5in]{../../analysis/pems/occ_flow_with_sample.pdf}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{frame}
%\begin{frame}
%\frametitle{References}
%\printbibliography
%\end{frame}

\end{document}
