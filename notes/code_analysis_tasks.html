<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>code_analysis_tasks</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.line-block{white-space: pre-line;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p>Wed Feb 28 09:56:47 PST 2018</p>
<p>Meeting with Nick</p>
<h1 id="code-analysis">Code analysis</h1>
<p>We can do a few different things with code:</p>
<ul>
<li><strong>static analysis</strong> inspect and describe it</li>
<li><strong>dynamic analysis</strong> run some portion of the code and see what happens</li>
<li><strong>transpile</strong> modify the code to make it more efficient while staying in the same language.</li>
<li><strong>compile</strong> compile into machine code.</li>
</ul>
<p>I’m interested in analyzing data analysis scripts that are roughly somewhere between 10 and 1000 lines of code.</p>
<p>Most of the analysis tasks I have in mind have are motivated by the potential to do some kind of transpiling. This is a different use case than seeking purely to understand the code.</p>
<h2 id="what-should-a-general-r-code-analysis-framework-look-like">What should a general R code analysis framework look like?</h2>
<p>I like the notion of “optimization passes”, meaning that we walk through the code and make one type of change. For example, an early optimization pass might be removing all unnecessary code.</p>
<p>It should be extensible in the sense that I would like to add information after profiling / running the code. The data structure should support this. We could potentially do this with attributes, but Nick pointed out one technical limitation that symbols cannot have attributes.</p>
<h2 id="what-would-i-like-a-general-static-code-analysis-system-to-identify">What would I like a general static code analysis system to identify?</h2>
<p>I’ll order these by priority. Then I can start thinking about the data structure I want for code analysis. In the below I see quite a bit about reorganizing code to some logical structure.</p>
<p><strong>Earliest place to run subset operations</strong></p>
<p>If we only need a subset of rows and columns to do the required task then we can filter the data early, even at the source. This saves memory and time for intermediate computations.</p>
<p><strong>Group semantic units</strong></p>
<p>Gather together code that must always run together. For example, to produce a plot we need all the plotting calls between <code>pdf(&quot;myplot.pdf&quot;)</code> and <code>dev.off()</code>.</p>
<p><strong>Statements or semantic units in data analysis code that actually produce output.</strong></p>
<p>If these statements execute, ie. build a plot or save some result to a file, then the script has run successfully.</p>
<p><strong>Unnecessary statements</strong></p>
<p>Then we can remove them.</p>
<p><strong>Vectorized and scalar valued functions</strong></p>
<p>Then we can better infer the sizes of the data that pass through.</p>
<p><strong>Calls / statements likely to be slow</strong></p>
<p>Think about machine learning for code- code and data sizes should be able to predict the timings / profiling information.</p>
<p><strong>How much memory any statement will consume</strong></p>
<p>Memory use and copying is notoriously hard to predict in R.</p>
<p><strong>When will a variable be copied</strong></p>
<p><strong>The random number generator is called</strong></p>
<p>This requires special handling for parallel applications.</p>
<p><strong>Variable lifetimes</strong></p>
<p>For example, the remainder of the code doesn’t use <code>x</code> so we can safely <code>rm(x)</code>.</p>
<p><strong>When is it necessary to keep the names</strong></p>
<p>I’ve ran into this as a particular problem- a default was to compute the names so the code took an order of magnitude longer than it should have. If the remainder of the code doesn’t use the names then we don’t ever need to do any operations on the names.</p>
<p><strong>Statements that can be made more efficient by data reorganization</strong></p>
<p>For example, <code>group by</code> operations can be done streaming if the data has been grouped at the source.</p>
<p><strong>How often special statements are used</strong></p>
<p>Language aspects such as control flow, superassignment, and nonstandard evaluation in general make code analysis more difficult. If we can know that code does or doesn’t use it then we can use specialized versions of the code analysis.</p>
</body>
</html>
