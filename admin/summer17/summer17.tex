% A simple template for LaTeX documents
% 
% To produce pdf run:
%   $ pdflatex paper.tex 
%


\documentclass[12pt]{article}

% Begin paragraphs with new line
\usepackage{parskip}  

% Change margin size
\usepackage[margin=1in]{geometry}   

% Graphics Example:  (PDF's make for good plots)
\usepackage{graphicx}               
% \centerline{\includegraphics{figure.pdf}}

% subfigures, side by side
\usepackage{subcaption}

% hyperlinks
\usepackage{hyperref}

% Blocks of code
\usepackage{listings}
\lstset{basicstyle=\ttfamily, title=\lstname}
% Insert code like this. replace `plot.R` with file name.
% \lstinputlisting{plot.R}

% Monospaced fonts
%\usepackage{inconsolata}
% GNU \texttt{make} is a nice tool.

% Supports proof environment
\usepackage{amsthm}

% Allows writing \implies and align*
\usepackage{amsmath}

% Allows mathbb{R}
\usepackage{amsfonts}

% Numbers in scientific notation
% \usepackage{siunitx}

% Use tables generated by pandas
\usepackage{booktabs}

% Allows umlaut and non ascii characters
\usepackage[utf8]{inputenc}

% Insert blank pages
\usepackage{afterpage}
%\afterpage{\null\newpage}

% norm and infinity norm
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\inorm}[1]{\left\lVert#1\right\rVert_\infty}

% Statistics essentials
\newcommand{\iid}{\text{ iid }}
\newcommand{\Exp}{\operatorname{E}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\Cov}{\operatorname{Cov}}

% Turn off bibliography header
\usepackage{etoolbox}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{center}
    \large Automatic Parallelism Through Code Analysis 

    \normalsize Clark Fitzgerald
\end{center}

\vspace{3\baselineskip}

For the 2017 Summer Research Application I plan to develop experimental software capable
of transforming serial R programs into parallel. This software will take
serial code and a description of the data to be analyzed in as an input,
and output parallel code which uses multiprocessing. The resulting software
will be made publicly available in a package called \texttt{autoparallel}.

This is useful because it allows R programs to scale up and use more
parallel computational resources available on modern machines. Since the
program conversion happens automatically this allows us to build more
intelligence into the system, freeing the user to think about the specifics
of the problem and write higher level code, knowing that the system will do
the best it can to find a way to parallelize the operation.

Parallel opportunities can be found through analysis of base R's apply family of functions,
which include \texttt{lapply, apply, sapply, tapply, by, mapply, Map, vapply, outer
by, replicate}. These are all variants of the map reduce computational model which
has been successful for implementing large scale parallel systems
\cite{dean2008mapreduce}.

I will apply the code analysis to several test cases including:
\begin{enumerate}
    \item Basic algorithms
    \item Statistical simulation
    \item Analysis of grouped data
\end{enumerate}

Quantifying the gains and overhead associated with various forms of
parallelism is important for identifying when and where it makes a
difference in the final performance as measured by program run time.

The initial program should be capable of automatically tuning the
parallelism of a 

will perform benchmarks using the microbenchmark
package to determine 


As an example, the below code calculates column medians for a random matrix
of size $n \times p$. Fix $n$ and we can empirically show that
parallelism with 2 cores based on process forking becomes more efficient
than the serial version for $p < P$.
\begin{verbatim}
x = matrix(rnorm(n * p), nrow = n)

# Calculating the column medians is 
column_medians = apply(x, 2, median)
\end{verbatim}

\bibliographystyle{plain}
\bibliography{../../citations,../../Rpackages} 

\end{document}
